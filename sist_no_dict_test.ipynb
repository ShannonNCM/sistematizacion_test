{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook es para la sistematizacion sin necesariamente usar un diccionario, solo para extraer ideas/palabras principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textacy\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "\n",
    "import funciones as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'solola'\n",
    "df = pd.read_excel('info.xlsx', sheet_name=event)\n",
    "\n",
    "preguntas = ['P1', 'P2', 'P3']\n",
    "expanded_responses = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nounphrases(x):\n",
    "    doc = nlp(x)\n",
    "    noun_phrases = list(textacy.extract.noun_chunks(doc, min_freq=1))\n",
    "    unique_phrases = set()\n",
    "    for phrase in noun_phrases:\n",
    "        lower_phrase = phrase.text.lower()\n",
    "        if not any(token.is_stop for token in phrase):\n",
    "            unique_phrases.add(lower_phrase)\n",
    "    return sorted(unique_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {}\n",
    "for pregunta in preguntas:\n",
    "    if pregunta in df.columns:\n",
    "        test_data[pregunta] = df[['Sector', pregunta]].dropna()\n",
    "        test_data[pregunta]['res'] = test_data[pregunta][pregunta].apply(extract_nounphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtienen las frecuencias de las palabras o frases que se extrajeron\n",
    "frequency_data = {}\n",
    "\n",
    "for pregunta, data in test_data.items():\n",
    "    all_phrases = [phrase for phrases in data['res'] for phrase in phrases]\n",
    "    \n",
    "    phrase_counts = Counter(all_phrases)\n",
    "    \n",
    "    frequency_df = pd.DataFrame(phrase_counts.items(), columns=['Pregunta', 'Frecuencia'])\n",
    "    frequency_df = frequency_df.sort_values(by='Frecuencia', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    frequency_data[pregunta] = frequency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se obtienen los dataframes de las frecuencias de manera que se puedan graficar con la spidergraph\n",
    "individual_dfs = {}\n",
    "\n",
    "# Iterate through the frequency data for each question\n",
    "for pregunta, freq_df in frequency_data.items():\n",
    "    # Transpose the DataFrame and rename the index to the question name\n",
    "    transposed_df = freq_df.set_index('Pregunta').T\n",
    "    transposed_df.index = [pregunta]  # Set the index to the question name\n",
    "    \n",
    "    # Filter columns where the values are greater than 1\n",
    "    filtered_transposed_df = transposed_df.loc[:, (transposed_df > 1).any()]\n",
    "    \n",
    "    # Add the filtered DataFrame to the dictionary\n",
    "    individual_dfs[pregunta] = filtered_transposed_df.fillna(0)\n",
    "\n",
    "df_p1 = individual_dfs['P1']\n",
    "df_p2 = individual_dfs['P2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shannon.cap\\OneDrive - Comisi贸n Presidencial De Gobierno Abierto y Electr贸nico\\Documentos\\GitHub\\sistematizacion_test\\funciones.py:98: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  values = np.append(values, values[0])\n",
      "c:\\Users\\shannon.cap\\OneDrive - Comisi贸n Presidencial De Gobierno Abierto y Electr贸nico\\Documentos\\GitHub\\sistematizacion_test\\funciones.py:98: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  values = np.append(values, values[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 600x600 with 1 Axes>, <PolarAxes: >)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se grafica usando la funcion que se definio en el archivo funciones.py\n",
    "f.graf_rad(df_p1, 'res_nodict/graphs/P1_freq.png')\n",
    "f.graf_rad(df_p2, 'res_nodict/graphs/P2_freq.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se guarda la informacion en un archivo de excel\n",
    "file_name = f'res_nodict/{event}.xlsx'\n",
    "with pd.ExcelWriter(file_name, engine='openpyxl') as writer:\n",
    "    for pregunta, data in test_data.items():\n",
    "        data.to_excel(writer, sheet_name=pregunta, index=False)\n",
    "        \n",
    "# Load the workbook to add images\n",
    "wb = load_workbook(file_name)\n",
    "\n",
    "# Add each image to its corresponding sheet\n",
    "for pregunta in test_data.keys():\n",
    "    sheet = wb[pregunta]  # Access the sheet for the current question\n",
    "    image_file = f'res_nodict/graphs/{pregunta}_freq.png'  # Image file name for the question\n",
    "    img = Image(image_file)  # Load the image\n",
    "    img.anchor = 'H2'  # Position to insert the image (adjust as needed)\n",
    "    sheet.add_image(img)  # Add the image to the sheet\n",
    "\n",
    "# Save the workbook with the images included\n",
    "wb.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'res_nodict/resultados_frecuencia_{event}.xlsx'\n",
    "with pd.ExcelWriter(file_name, engine='openpyxl') as writer:\n",
    "    for pregunta, freq_df in frequency_data.items():\n",
    "        freq_df.to_excel(writer, sheet_name=f'{pregunta}_freq', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
