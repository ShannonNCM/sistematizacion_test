{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se importa el archivo de excel\n",
    "df = pd.read_excel('info.xlsx', sheet_name='Hoja1')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por el momento me va a servir divididr el dataframe en las preguntas que se hicieron\n",
    "ans_p1 = df[['Sector','P1']].dropna()\n",
    "ans_p2 = df[['Sector','P2']].dropna()\n",
    "ans_p3 = df[['Sector','P3']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans_p1\n",
    "#ans_p2\n",
    "#ans_p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\n",
    "    'datos estadisticos' : 'Datos',\n",
    "    'ciberseguridad' : 'Ciberseguridad',\n",
    "    'gobernanza' : 'Governanza',\n",
    "    'legal' : 'Leyes',\n",
    "    'leyes' : 'Leyes',\n",
    "    'seguridad' : 'Ciberseguridad',\n",
    "    'capacitacion' : 'Capacitacion'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para extraer las palabras segun lo que se establecio en el diccionario\n",
    "def extract(text, dict):\n",
    "    found_keywords = [] #vector para guardar las palabras encontradas\n",
    "    for keyword in dict:\n",
    "        if keyword.lower() in text.lower(): #para hacer match independiente de mayusculas\n",
    "            found_keywords.append(dict[keyword])\n",
    "    return found_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         [Governanza, Leyes]\n",
       "1     [Ciberseguridad, Leyes, Ciberseguridad]\n",
       "2                            [Ciberseguridad]\n",
       "3            [Ciberseguridad, Ciberseguridad]\n",
       "4     [Ciberseguridad, Leyes, Ciberseguridad]\n",
       "5            [Ciberseguridad, Ciberseguridad]\n",
       "6                            [Ciberseguridad]\n",
       "7                                          []\n",
       "8                                          []\n",
       "9                                          []\n",
       "10                                         []\n",
       "11                                         []\n",
       "12                                         []\n",
       "13                                         []\n",
       "14                                         []\n",
       "15                                         []\n",
       "16                                         []\n",
       "17                                         []\n",
       "19                                         []\n",
       "20           [Ciberseguridad, Ciberseguridad]\n",
       "21                                         []\n",
       "22                                         []\n",
       "23           [Ciberseguridad, Ciberseguridad]\n",
       "24           [Ciberseguridad, Ciberseguridad]\n",
       "25           [Ciberseguridad, Ciberseguridad]\n",
       "26           [Ciberseguridad, Ciberseguridad]\n",
       "27                                         []\n",
       "28                             [Capacitacion]\n",
       "Name: P1, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_p1['P1'].apply(lambda text: extract(text, dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use esto para cuando solamente estaba procesando las palabras directamente sin usar un diccionario, \n",
    "\n",
    "# se define la funcion que se va a usar para poder extraer las palabras clave\n",
    "def extract_keywords(text, keywords):\n",
    "    '''esta parte aplica el modelo de lenguaje spacy al texto que se esta ingresando y se guarda en 'doc'\n",
    "    'doc' es un objeto Doc de spacy, que es un contendor para el texto procesado, contiene 'tokens'\n",
    "    individuales (palabras o puntuaciones) junto con toda la informacion linguistica que spacy ha \n",
    "    computado'''\n",
    "    doc = nlp(text)\n",
    "    '''es una 'list comprehension', que es una forma concisa de crear listas en Python. \n",
    "    for token in doc -> hace un ciclo en cada token (palabra, puntuacion) en el texto procesado (doc)\n",
    "    if token.lemma_ in keywords -> revisa si el lemma del token esta en 'keywords', donde el lemma es\n",
    "                                    la base o forma diccionario de una palabra\n",
    "    token.text -> extrae el texto original del token que hace match, si el token coincide con una de las\n",
    "                    keywords, agrega la forma original de la palabra a la lista de palabras extraidas'''\n",
    "    extracted = [token.text for token in doc if token.lemma_ in keywords]\n",
    "    return extracted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
